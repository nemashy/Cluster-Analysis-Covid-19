---
title: \vspace{3.5in} Cluster Analysis Assignment
author: "Nyasha Mashanda"
date: "`r Sys.Date()`"
bibliography: "bibliography.bib"
output:
  bookdown::pdf_document2:
    keep_tex: true

---
.
\pagebreak
\abstract

The novel COVID-19 corona virus is still not well understood and there are many open questions related to patterns in its spread. The goal of this assignment is to discover if there are any regional patterns that exist using cluster analysis.


The assignment uses COVD-19 pandemic data collected from Our World In Data site [@WorldInData]. The data contains 29 indicators related to the
COVID-19 cases for 208 countries. The data set is updated daily from when the pandemic started. For this assignment, a subset of the
data will be used; this subset consists of all the information on the pandemic on the 02 of September
2020.


There are three kinds of clustering methods that will be explored in this analysis: hierarchical, partitioning and density based methods. In order to determine any regional patterns, the number of clusters will be limited to 6, resembling the six regions that are: Africa, Asia, Europe, North America, Oceania and South America.
\pagebreak




```{r setup, include=FALSE}

# Loading all necessary packages or install if packages don't exist

knitr::opts_chunk$set(echo = TRUE)
if(!require(readxl)) install.packages("readxl", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(cluster)) install.packages("cluster", repos = "http://cran.us.r-project.org")
if(!require(NbClust)) install.packages("NbClust", repos = "http://cran.us.r-project.org")
if(!require(fpc)) install.packages("fpc", repos = "http://cran.us.r-project.org")
if(!require(mice)) install.packages("mice", repos = "http://cran.us.r-project.org")
if(!require(VIM)) install.packages("VIM", repos = "http://cran.us.r-project.org")
if(!require(factoextra)) install.packages("factoextra", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(purrr)) install.packages("purrr", repos = "http://cran.us.r-project.org")
if(!require(tidyr)) install.packages("tidyr", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(visdat)) install.packages("visdat", repos = "http://cran.us.r-project.org")
if(!require(Hmisc)) install.packages("Hmisc", repos = "http://cran.us.r-project.org")
if(!require(missForest)) install.packages("missForest", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
```

\newpage
```{r Variables-tab, echo=FALSE, message=FALSE}

# Display this on the first page to see what and from where each variable was collected.
owid_covid_codebook <- read_csv("owid-covid-codebook.csv")
knitr::kable(owid_covid_codebook, digits = 5, caption = "Variables") %>%
  kable_styling(full_width = F, font_size = 7) %>%
  column_spec(1, border_left = T) %>%
  column_spec(2, border_right = T)

#View(owid_covid_codebook)
```
.
\pagebreak

\newpage


# Exploratory Data Analysis

## Importing the Data

```{r include=FALSE}

# Reading the data
df1 <- read_excel("owid-covid-data.xlsx", sheet = "Data")

# Check if data has been imported correctly
head(df1) 
tail(df1)

# Look at the structure of the data
str(df1)


```

The data was exported to a dataframe from an excel file "owid-covid-data.xlsx". The first step was to check if the data has been imported correctly using the head() and tail() functions. The file was confirmed to have been imported correctly. The next step included checking the structure of the dataframe and also the variables in the data (See variables in Table \@ref(tab:Variables-tab)). Location, iso_code, continent and date were found to be in character format while the rest of the variables are numerical. The date variable is expected to be in a date format. However, since this column has only one date, the column will not be used for analysis and will be removed from the dataframe.

The next step was to visualize the distribution of the variables and this was done using box and whisker plots. This is a very important step as it may highlight outliers and incorrectly recorded values that are out of the expected range. 

## Distribution of variables

In plotting the distribution of numerical variables, the variables were divided into three groups. This makes it easier to analyse the variables. The variable in the first group are shown in Fig \@ref(fig:group-1).


```{r group-1, echo=FALSE, warning=FALSE, fig.cap="Group 1 of Variables"}

# Plot box and whisker for the first 9 variables

df1 %>%
  keep(is.numeric) %>%
  select(c(1:9)) %>%
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_boxplot(
      # custom boxes
        color="blue",
        fill="blue",
        alpha=0.2,
        
        # Notch?
        notch=FALSE,
        notchwidth = 0.8,
        
        # custom outliers
        outlier.colour="black",
        outlier.fill="black",
        outlier.size=2
    )



```

Most of the variables in this group have many outliers making the distribution of values less clear. This indicates that a clustering method that is less susceptible to outliers can be used.

Taking a deeper look into the plots, it is immediately obvious that new_cases_smoothed_per_million might has an incorrectly recorded value given that it has a negative outlier. To deal with the negative value in new_cases_smoothed_per_million the data was explored to identify the observation with the negative value. This data point was found to be belonging to Luxembourg. Upon further investigation, Luxembourg seems to have negative values for new_cases_smoothed and new_cases_smoothed_per_million. This is probably because the new_cases_smoothed_per_million is derived from new_cases_smoothed. The negative datapoints were replaced with the regional mean.


```{r include=F}
# Find the obserservation with negative value
Lx = df1 %>% 
  filter(new_cases_smoothed_per_million < 0)
head(Lx)
```


```{r include=FALSE, warning=FALSE}

# Replace negative values with continental mean
df1  = df1 %>% 
  group_by(continent) %>%
  mutate(new_cases_smoothed_per_million = ifelse(new_cases_smoothed_per_million < 0,
                                                 mean(new_cases_smoothed_per_million),
                                                 new_cases_smoothed_per_million),
         new_cases_smoothed = ifelse(new_cases_smoothed < 0,
                                     mean(new_cases_smoothed),
                                     new_cases_smoothed))
```


 

For variables in Fig \@ref(fig:group-2), aged_65_older and median age observations are more spread without any outliers. The rest of the variable have multiple outliers. 


```{r group-2, echo=FALSE, warning=FALSE, fig.cap="Group 2 of Variables"}
# Plot box and whisker plots for variables 10 to 16
df1 %>%
  keep(is.numeric) %>%
  select(c(10:17)) %>%
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_boxplot(
            # custom boxes
        color="blue",
        fill="blue",
        alpha=0.2,
        
        # Notch?
        notch=FALSE,
        notchwidth = 0.8,
        
        # custom outliers
        outlier.colour="black",
        outlier.fill="black",
        outlier.size=2
    )

```

The observations for median age look reasonable given that a smaller percentage of the population should be of age above 65. The median age of most countries is expected to be below 50 given that there are usually more young people than older people in country. Countries like Japan and Italy seem to have the highest percentage of older people with a median age of 48.2 and 47.9 respectively. The Niger and Uganda have the youngest population with a median age of 16.1 and 15.4. In general, European countries seems to have an older society while Africa countries have a much younger population.

Monaco and Singapore have the highest population densities while China has the highest population. As a result, these countries stand out as outliers with regards to population variables.

New Deaths per million are highest in north and South America.

```{r group-3, echo=FALSE, warning=FALSE, fig.cap="Group 3 of Variables"}
# Plot box and whisker plots for variables 17 to 16
df1 %>%
  keep(is.numeric) %>%
  select(c(18:26)) %>%
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_boxplot(
            # custom boxes
        color="blue",
        fill="blue",
        alpha=0.2,
        
        # Notch?
        notch=FALSE,
        notchwidth = 0.8,
        
        # custom outliers
        outlier.colour="black",
        outlier.fill="black",
        outlier.size=2
    )

```

The observations for variable in Fig \@ref(fig:group-3) look more spread with less outliers. The data also suggest that there are generally more male smokers than female smokers.

\pagebreak

# Missing values

```{r include=F}
summary(df1)
```

Running a summary on the dataframe shows that there are various columns with missing data. The VIM package was used to visualize the missing data.

```{r echo=F, missing-distr, fig.cap="Missing data distribution"}
# Visualise to see rows/columns with missing data
#missing_data_visual

aggr_plot <- VIM::aggr(df1, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df1), cex.axis=.5, gap=3, ylab=c("Histogram of missing data","Pattern"), plot = F)
plot(aggr_plot, cex.axis=.5, gap=3, ylab=c("Histogram of missing data","Pattern"))
```


```{r echo=FALSE, fig.cap="Missing Data Visual"}

# Creating table
missing_data_table = aggr_plot$missings %>%
  filter(Count > 0) %>%
  arrange(desc(Count)) %>%
  mutate(Percentage = Count*100/208)

```
The visual shows that most of the rows in the data have missing values in one or more columns. Therefore, simply omitting the missing data will lead to loss of most of the data. 

```{r missing-data-table, echo=FALSE}
# Displaying table for missing data on each variable
knitr::kable(missing_data_table, digits = 3, caption = "Missing data visualisation") %>%
  kable_styling(full_width = F, font_size = 7) %>%
  column_spec(1, border_left = T) %>%
  column_spec(3, border_right = T)
```


Also, Table \@ref(tab:missing-data-table), taken from the histogram in Fig \@ref(fig:missing-distr) shows that numerous variables have a very high number of missing values including handwashing_facilities, extreme_poverty, male smokers and female smokers. It is generally not good working with data or columns that have a high percentage of missing data.Therefore, the following approaches will be taken to tackle the missing data in the variables.

## Imputation using internet data

There are various sources that were used to collect the data including the European Center for Disease Prevention and Control and the World Bank Data for the original dataset. However, some of the data can be found on wikipedia and various internet sources. Consequently, looking for the data before applying an imputation algorithms is much better. Although the data was not exactly be the same in most cases, the values were found to be very similar for the column observations with no missing data, thereby supporting the imputation method.


```{r include=FALSE}

# Determine the percentage of rows with missing data

missing_rows <- sum(!complete.cases(df1))
total_rows <- nrow(df1)
percentage_of_missing_rows <- missing_rows/total_rows * 100
percentage_of_missing_rows

```

Population density missing values were imputed using the data from wikipedia [@PopulationDensity]. The data for all the countries with missing values was available, except for the Falkland Islands. Median age missing values were imputed using the data found from the CIA [@MedianAge]. Using this site, only three countries had values for median age that could not be found. Aged_65_older missing values were imputed using 2019 data from wikipedia [@Aged65]. On this site, the data available was on Syria, Taiwan and British Virgin Islands. The rest of the countries values could not be imputed using this method. Median age above 75 years old was ignored since there was not much data on the internet regarding this variable.

Extreme poverty values signify a population percentage with an income of less than $1.90 a day. The data used for imputation in this variable was taken from from wikipedia [@Poverty]. 



```{r include=F}

# Imputing population density missing values.

# The process includes finding countries with
# missing data in a column of interest and 
# then impute the missing data with data from
# a source

df2 <- df1[is.na(df1$population_density),] # Dataframe with missing value in a column
missing_data_countries <-  df2$location #missing_data_countries
imputations <- c(19.83, 2.25, 92, 652.11, 804.14, 898.28, 924.49, 140.13, 65.64, NA, 0.21)
position_in_vector <- which(df1$location %in% missing_data_countries)
df1$population_density[position_in_vector] <-  imputations # Imputing the data

sum(is.na(df1$population_density)) # Check if data has been imputed

```



```{r include=F}

# Imputing median_age missing values.

df3 <- df1[is.na(df1$median_age),]
missing_data_countries <-  df3$location
#missing_data_countries
median_ages  <- c(46.2, 37.2, 35.5, 44.3, 44.6, 37.5, 30.5, 43.7, 55.4, 45.2, NA, 35.7, 43.6, NA, 37.2, 40.5, 34.9, 34.3, 34.8, 36.5, 41.1, 34.6, 32.8, NA)
position_in_vector <- which(df1$location %in% missing_data_countries)

df1$median_age[position_in_vector] <-  imputations


```



```{r include=FALSE}

# Imputing aged_65_older missing values.

df4 <- df1[is.na(df1$aged_65_older),]
missing_data_countries <-  df4$location
#missing_data_countries
median_ages  <- c(NA, 4.3, 13.86, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 18.6, NA, NA, NA, NA, NA, NA, NA, NA, NA )
position_in_vector <- which(df1$location %in% missing_data_countries)

df1$aged_65_older[position_in_vector] <-  median_ages

sum(is.na(df1$aged_65_older))

```


```{r include=FALSE}

# Imputing extreme_poverty missing values.

df4 <- df1[is.na(df1$extreme_poverty),]
missing_data_countries <-  df4$location
#missing_data_countries
extreme_pov <- rep(NA, length(missing_data_countries))

extreme_pov[c(1, 2, 3, 4, 8, 9, 11, 12, 13, 16, 20, 22, 23, 25, 29, 32, 34, 35, 36, 38, 39, 40, 47, 48, 50, 51, 52, 59, 69, 76, 86, 87, 88)] <- c(47.6, 16.1, 3.2, 66.3, 49.7, 53.5, 42.7, 14.9, 42, 0, 0.2, 0, 7.3, 6.1, 1.7, 62.1, 0, 0, 0, 0, 0, 0, 0, 0, 5.5, 0, 0, 13.9, 1.7, 3.4, 14, 23.4, 10.2)

position_in_vector <- which(df1$location %in% missing_data_countries)
df1$extreme_poverty[position_in_vector] <-  extreme_pov

sum(is.na(df1$extreme_poverty))
```

Cardiovascular death rate could not be imputed using this method due to insufficient data.
```{r include=FALSE}
df4 <- df1[is.na(df1$cardiovasc_death_rate),]
missing_data_countries <-  df4$location
#missing_data_countries

```

```{r include=FALSE}

# Imputing life_expectancy missing values.

df4 <- df1[is.na(df1$life_expectancy),]
missing_data_countries <-  df4$location
#missing_data_countries

life_exp <- c(82.6, 80.6, 71.95)
position_in_vector <- which(df1$location %in% missing_data_countries)

df1$life_expectancy[position_in_vector] <-  life_exp

sum(is.na(df1$life_expectancy))
```



The handwashing facilities variable was not imputed upon using this method because there was no new data found on the internet.
The hospital bed per thousand information was found to be too old for example Chad which had data for 2005. Given that there are many years between the time the data was collected and this year, the data was ignored.

For life expectancy, only three observations were found to have missing life expectancy values. Imputation was done using the world bank data on life expectancy [@LifeExpectancy].


After imputation using the data from the internet, there were still missing values in some of the variables. For population density, extreme poverty, gdp per capita, hospital beds per thousand, aged 65 and older and aged 70 and older, a better imputation method was to replace missing values with column regional means given that countries in the same regions are more likely to hold similar values for these variables. This is better than using the column mean which takes into account all regions.


```{r include=FALSE}
# For the gdp per capita the missing values will be replaced by the mean for each region under the assumption that countries that are closer to each other usually have similar rates of poverty measures/gdp_per_capita, hospital beds per thousand, aged_65_older and aged_70_older, population_density, extreme_poverty


df6 <- df1 %>%
    group_by(continent) %>%
    mutate(
        population_density=ifelse(is.na(population_density),mean(population_density,na.rm=TRUE),population_density),
        extreme_poverty=ifelse(is.na(extreme_poverty),mean(extreme_poverty,na.rm=TRUE),extreme_poverty),
        gdp_per_capita=ifelse(is.na(gdp_per_capita),mean(gdp_per_capita,na.rm=TRUE),gdp_per_capita),
        hospital_beds_per_thousand=ifelse(is.na(hospital_beds_per_thousand),mean(hospital_beds_per_thousand,na.rm=TRUE),hospital_beds_per_thousand),
        aged_65_older=ifelse(is.na(aged_65_older),mean(aged_65_older,na.rm=TRUE),aged_65_older),
        aged_70_older=ifelse(is.na(aged_70_older),mean(aged_70_older,na.rm=TRUE),aged_70_older)
  
    )
```


Due to hand_washing_facilities having missing data greater than 50%, the variable was removed since it is most likely that the imputed values will be far from the actual values.

After imputation using the data scrapping and regional averages, the looks visualisation is shown below:
```{r include=F}

# Remove handwashing_facilities since there is not enough 
# data for imputation

df7 <- select(df6,-handwashing_facilities)
aggr_plot <- VIM::aggr(df7, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df7), cex.axis=.5, gap=3, ylab=c("Histogram of missing data","Pattern"), plot = T)

```


```{r new-vis, echo=F, fig.cap="Visual after imputation", fig.width=4, fig.height=4  }
plot(aggr_plot, cex.axis=.5, gap=3, ylab=c("Histogram of missing data","Pattern"))
```

At this point, the highest percentage of missing values is found in male smokers and female smokers having 34% and 33% missing values as show in Fig \@ref(fig:new-vis). For the these variables and others that have missing values imputation algorithms will be explored and the one that gives the best results will be chosen.


## Mice

The mice package allows multivariate imputation by chained equations. MICE assumes that the missing data are Missing at Random (MAR), which means that the propensity for a data point to be missing is not related to the missing data but is related to some of the observed data [@MissingData]. In this section, the MICE package will be used on the remaining variables with missing data that are cardiovasc_death_rate, diabetes prevalence, female and male smokers.

The number of multiple imputations was set to 5, method was set to classification and regression trees and the maximum number of iterations set to 500. 5 datasets were created and the goodness of fit is shown in Fig \@ref(fig:dens-plot). The graphs of imputed values(red) closely resembles that of the available values(blue). This shows that the imputation process was good. 


```{r include=FALSE}


# Impute missing data using the mice package

#imputed_data <- mice(df7,m=5,maxit=50, method='cart', seed=500)
#summary(imputed_data)
#save(imputed_data, file = "replaced_missing_data.RData")
load("replaced_missing_data.RData")

sum(is.na(imputed_data)) # Check if imputations have been done
```

```{r dens-plot, echo=FALSE, fig.cap="Density plot"}
# Check the quality of imputations

mice::densityplot(imputed_data)

```


One dataset was randomly selected from the five datasets. This will not affect the outcome significantly given that the datasets have very similar properties. This dataset was named mice_data_for_clustering.

```{r include=FALSE}
# Select one of the imputed datasets

completedData <- mice::complete(imputed_data, 2)
#View(completedData)
#str(completedData)

# Remove isocode, continent and date

df8 <- completedData[,c(-2,-3,-4)]
rownames(df8) <- df8$location

# Removing country names
mice_data_for_clustering <- df8[,-1]

```

## Hmisc
A second dataset was created using the Hmisc package. Hmisc is a multiple purpose package useful for data analysis, high – level graphics, imputing missing values, advanced table making, model fitting & diagnostics (linear regression, logistic regression & cox regression) etc. Hmisc assumes linearity in the variables being predicted. There is also the Amelia and mi package that are used for imputation but these will not be considered for this analysis.


```{r include=FALSE}
# Impute missing data using the Hmisc package

df7.mis <- prodNA(df7, noNA = 0.1)

impute_arg <- aregImpute(~ cardiovasc_death_rate 
                         + diabetes_prevalence + female_smokers + male_smokers, data = df7.mis, n.impute = 5)

completeData2 <- impute.transcan(impute_arg, imputation=1, data=df7.mis, list.out=TRUE,pr=FALSE, check=FALSE) 

#head(completeData2)
#class(completeData2)

df_Hmisc = df7 # Make a copy of df7

df_Hmisc$cardiovasc_death_rate = completeData2$cardiovasc_death_rate
df_Hmisc$diabetes_prevalence = completeData2$diabetes_prevalence
df_Hmisc$female_smokers = completeData2$female_smokers
df_Hmisc$male_smokers = completeData2$male_smokers

df_Hmisc <- completedData[,c(-2,-3,-4)]
rownames(df_Hmisc) <- df_Hmisc$location

# Removing country names
df_Hmisc_for_clustering <- df_Hmisc[,-1]

#summary(df_Hmisc_for_clustering)
```

The imputations were made on the dataset and the resulting dataset was named df_Hmisc_for_clustering. The two datasets, mice_data_for_clustering and df_Hmisc_for_clustering, were used for clustering and the results were compared.

# Cluster Analysis

Before initiating the cluster analysis, continent, date and iso_code variables were removed from the dataset as they were not be useful for the analysis. 
While performing cluster analysis, the number of clusters was set to 6 given that we have six distinct regions in the data that are Africa, Asia, Europe, North America, Oceania and South America. In order to quantify the goodness of fit for each clustering method, the average silhouette method will be used to  determine the quality of the clusters. The optimum number of clusters in a dataset will have the maximum average silhouette width (ASW).

## Heirachical clustering

Hierarchical clustering involves creating clusters that have a predetermined ordering from top to bottom. In this analysis, complete, single, average, median and centroid linkage were applied to the dataset.

```{r include=FALSE}
data.out <- mice_data_for_clustering
```


```{r include=F}
# Hierarchical clustering

# Compute pairwise distance matrices
dist.out <- dist(data.out,
                 method = "euclidean")
# Hierarchical clustering results
hc <- hclust(dist.out,
             method = "complete")

# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc_single <- hclust(dist.out,
             method = "single")
# Visualization of hclust
plot(hc_single, labels = F,-1)
plot(silhouette(cutree(hc_single,6),dist.out))

hc <- hclust(dist.out,
             method = "average")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc <- hclust(dist.out,
             method = "median")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc <- hclust(dist.out,
             method = "centroid")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))


```
The results from heirachical clustering are shown in Table \@ref(tab:hr-table).

```{r hr-table, echo=F}
# Display heirachical clustering results
hc_results <- read_excel("HeirachicalResults.xlsx")
knitr::kable(hc_results, digits = 5, caption = "Heirachical Clustering Results") %>%
  kable_styling(full_width = F, font_size = 7) %>%
  column_spec(1, border_left = T) %>%
  column_spec(2, border_right = T)

cluster_for_countries = tibble(Country = hc[["labels"]], Group = silhouette(cutree(hc_single,6),dist.out)[,1])


```

The results show that single linkage had the best results with an ASW of 0.83. The quality of the single linkage cluster is therefore high and the countries in the cluster are more similar. Single linkage clusters have all countries are in one cluster except for 2(India), 3(Aruba, Sint Maarten, Guam), 5(United States), 6(Brazil) where the number ahead of the country is the cluster number. Therefore, India, Brazil and United States are clearly significant outliers. Given that these clusters show no evidence of regional interactions for 6 continents, there is insignificant regional pattern shown using the single linkage clusters.

## K-means

K-means clustering aims to identify the best k-centroids in the data that will be allocated every other data observations. This will result in k clusters for the data.

```{r k-table, echo=F, fig.width=4, fig.height=4 }

# Using k-means clustering
k.max <- 10

sil <- rep(0, k.max)
# Compute the average silhouette width for
# k = 2 to k = 10
set.seed(100)
for(i in 2:k.max){
  
  km.res <- kmeans(data.out, centers = i, nstart = 25)
  ss <- silhouette(km.res$cluster, dist(data.out))
  sil[i] <- mean(ss[, 3])
  if (i == 2) {
    clusters_2 = km.res$cluster
  }
  if (i == 6) {
    clusters_6 = km.res$cluster
  }
}

## Create a dataframe to show the cluster 6 groupings
clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))

knitr::kable(clusters_6_dataframe, digits = 3, caption = "K-means") %>%
  kable_styling(full_width = F, font_size = 7) %>%
  column_spec(1, border_left = T) %>%
  column_spec(4, border_right = T)

```

```{r k-m, echo=F, fig.cap="K-means result using the Mice dataset" }
# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])
```



The K-means clustering results show that the ASW for six clusters is 0.68 as shown in Fig \@ref(fig:k-m). The diagram suggest that the best number of cluster in the data is 2 with an ASW of 0.974. As shown in Table \@ref(tab:k-table), when looking at six clusters, more than 80% of African countries fall in clusters 4 and 5, around 70 % of Asian countries fall in cluster 4 and 5, 88% of North American countries fall in cluster 4, 87% of Oceania countries fall in clusters 4, 76 of South American Countries fall in cluster 4 and 6. This information seem to suggests that there are mainly two clusters that is 4 and 5. This is further supported by the ASW of 0.9736113 for two clusters.


## K-Mediods

```{r echo=F, fig.width=4, fig.height=4}
# Using k-medoids clustering
set.seed(100)
pam.out <- pam(data.out, 6)


# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){
  pam.out <- pam(data.out, i)
  sil[i] <- pam.out[["silinfo"]][["avg.width"]]
  if (i==6) {
    class_avg_width = pam.out[["silinfo"]][["clus.avg.widths"]]
    clusters_6 = pam.out$clustering
  }

}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))

```

```{r k-med, echo=F, fig.cap="K-mediods results using the Mice dataset"}
# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])
#class_avg_width
```


The ASW for six clusters is 0.61 while that of 2 clusters is the maximum at 0.974 shown in Fig \@ref(fig:k-med). The information also suggest that the optimum number of clusters is 2. Over 90% of African countries belong to group 1, 2 and 3, 75% of Asian countries belong to group 1, 2 and 3. 86% of European countries belong to group 2 and 3, 91% of North American countries belong to group 2 and 3, 75% of Oceania countries belong to group 3 and more than 90% of South American countries belong to group 1, 2 and 3. These results show that there are at most three main clusters in the data and there is no specific regional pattern that can be seen. The PAM method also suggests that the optimum number of clusters in 2.



## Clara
```{r echo=FALSE, fig.width=4, fig.height=4}
# Using Clara
clara.out <- clara(data.out, 6, samples=10)

# Using k-medoids clustering
set.seed(100)


# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){
  clara.out <- clara(data.out, i, samples=10)
  sil[i] <- clara.out[["silinfo"]][["avg.width"]]
  if (i==6) {
    class_avg_width = clara.out[["silinfo"]][["clus.avg.widths"]]
    clusters_6 = clara.out$clustering
  }

}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))

```


```{r clara, echo=F, fig.cap="Clara results using the Mice dataset"}
# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)
#print(sil[6])
#print(sil[2])
#class_avg_width
```

Clara results in Fig 9 show an ASW of 0.566 for six clusters. In addition, more than 91% of African countries are found in group 1, 2 and 3. More than 77% of Asian countries are found in group 1, 2 and 3. More than 76% of countries in Europe are found in groups 2 and 3. More than 91% of North American countries are found in groups 2 and 3. More than 87% of Oceanian countries are found in groups 2 and 3 while more than 90% of South American countries are found in group 1, 2 and 3. Again, the information suggest that there are at most the main clusters in the data. 

## DBSCAN

Density based scanning was tested and in order to get six main clusters on the data the epsilon value was set to 47 000 and the min points to 3. This AWS was -0.21 which indicates that the clusters are of poor quality and objects are less similar in their own cluster. This may well mean that the data either has too many of too few clusters. The DBSCAN method also pick up many outliers in the data and very few countries belonging to groups. This method will not be explored for further analysis given that it does not give any good results.

```{r include=FALSE,  fig.cap="DBSCAN results using the Mice dataset", fig.width=4, fig.height=4}
# Using DBSCAN
t = scale(data.out)
db <- fpc::dbscan(data.out, eps = 47000, MinPts =3 )
db[["cluster"]]
sil.dbscan <- silhouette(db$cluster, dist(t))
summary(sil.dbscan)
plot(sil.dbscan, col = 2:3, main = "Silhouette plot")
```

## Using the Hmisc dataset

Results from runnnig the algorithms with the Hmisc dataset were very similar to those from the Mice dataset hence the results will not be displayed. The reader can run the scripts in the R markdown file in order to have the plots displayed.

```{r include=FALSE, fig.cap="K-means results using the Hmisc dataset", fig.width=4, fig.height=4}
data.out <- df_Hmisc_for_clustering 
```


```{r include=F}

# Using k-means clustering
k.max <- 10

# data.out <- df_Hmisc_for_clustering[-22,-23]
sil <- rep(0, k.max)
# Compute the average silhouette width for
# k = 2 to k = 10
set.seed(100)
for(i in 2:k.max){
  
  km.res <- kmeans(data.out, centers = i, nstart = 25)
  ss <- silhouette(km.res$cluster, dist(data.out))
  sil[i] <- mean(ss[, 3])
  if (i == 2) {
    clusters_2 = km.res$cluster
  }
  if (i == 6) {
    clusters_6 = km.res$cluster
  }
}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))



# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])

```


```{r include=F, fig.cap="HC results using the Hmisc dataset", fig.width=4, fig.height=4}
# Hierarchical clustering
# Compute pairwise distance matrices
dist.out <- dist(data.out,
                 method = "euclidean")
# Hierarchical clustering results
hc <- hclust(dist.out,
             method = "complete")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc_single <- hclust(dist.out,
             method = "single")
# Visualization of hclust
plot(hc_single, labels = F,-1)
plot(silhouette(cutree(hc_single,6),dist.out))



hc <- hclust(dist.out,
             method = "average")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc <- hclust(dist.out,
             method = "median")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc <- hclust(dist.out,
             method = "centroid")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))
```



```{r include=F, fig.cap="K-mediods results using the Hmisc dataset", fig.width=4, fig.height=4}
# Using k-medoids clustering
set.seed(100)
pam.out <- pam(data.out, 6)


# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){
  pam.out <- pam(data.out, i)
  sil[i] <- pam.out[["silinfo"]][["avg.width"]]
  if (i==6) {
    class_avg_width = pam.out[["silinfo"]][["clus.avg.widths"]]
    clusters_6 = pam.out$clustering
  }

}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))


# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])
#class_avg_width
```

```{r include=FALSE, echo=F, fig.cap="Clara results using the Hmisc dataset", fig.width=4, fig.height=4}
# Using Clara
clara.out <- clara(data.out, 6, samples=10)
# Silhouette plot
plot(silhouette(clara.out), col = 2:3, main = "Silhouette plot")



# Using k-medoids clustering
set.seed(100)


# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){
  clara.out <- clara(data.out, i, samples=10)
  sil[i] <- clara.out[["silinfo"]][["avg.width"]]
  if (i==6) {
    class_avg_width = clara.out[["silinfo"]][["clus.avg.widths"]]
    clusters_6 = clara.out$clustering
  }

}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))


# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])
#class_avg_width
```

```{r include=FALSE}
# Using DBSCAN
t = scale(data.out)
db <- fpc::dbscan(data.out, eps = 47000, MinPts =3 )
db[["cluster"]]
sil.dbscan <- silhouette(db$cluster, dist(t))
summary(sil.dbscan)
plot(sil.dbscan, col = 2:3, main = "Silhouette plot")
```

# Dimension reduction

A correlation plot of all the numerical variables (Fig \@ref(fig:corr-plot)) shows that some of variables in the dataset are highly correlated. Therefore, the size of the dataset can be reduced but keeping most of the information in the dataset using dimension reduction techniques. In this exercise PCA will be used to reduce the size of the data and clustering will be performed on the reduced data.

```{r corr-plot, echo=FALSE, fig.cap="Correlation Plot", fig.width=4, fig.height=4}
df_correlation_plot <- df_Hmisc_for_clustering %>%
  keep(is.numeric)

correlation_matrix <- cor(df_correlation_plot)
corrplot(correlation_matrix, method="circle", tl.pos='n')
```


```{r include=F}
# Attempt clustering after dimension reduction
# Using PCA

pca.out <- princomp(data.out, cor=T,scores=T)
Variance<-(pca.out$sdev)^2
max_Var<-round(max(Variance),1)
Components<-c(1:25)
Components<-as.integer(Components)

df10 =pca.out$scores
df11 =  df10[,c(1:4)]

# Average silhouette method for k-means clustering
k.max <- 10
data.out <- df11
# data.out <- df_Hmisc_for_clustering[-22,-23]
sil <- rep(0, k.max)
# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){

km.res <- kmeans(data.out, centers = i, nstart = 25)
ss <- silhouette(km.res$cluster, dist(data.out))
sil[i] <- mean(ss[, 3])
}
# Plot the average silhouette width
plot(1:k.max, sil, type = "b", pch = 19,
frame = FALSE, xlab = "Number of clusters k")
abline(v = which.max(sil), lty = 2)

# Partition around medoids
pam.out <- pam(data.out, 4)
head(pam.out$cluster)
plot(pam.out)

pam.out$silinfo$avg.width

k.max = 20
for (k in 2:k.max) {
  pam.out <- pam(data.out, k)
  sil[k] = pam.out$silinfo$avg.width
}

plot(1:k.max, sil, type = "b", pch = 19,
frame = FALSE, xlab = "Number of clusters k")
abline(v = which.max(sil), lty = 2)

print(sil[6])
print(sil[2])

# Using Clara
clarax <- clara(data.out, 6, samples=10)
# Silhouette plot
plot(silhouette(clarax), col = 2:3, main = "Silhouette plot")

clarax$silinfo$avg.width

for (k in 2:k.max) {
  pam.out <- pam(data.out, k)
  sil[k] = pam.out$silinfo$avg.width
}

plot(1:k.max, sil, type = "b", pch = 19,
frame = FALSE, xlab = "Number of clusters k")
abline(v = which.max(sil), lty = 2)

t = scale(data.out)
db <- fpc::dbscan(data.out, eps = 2.7, MinPts = 1)
db[["cluster"]]
sil.dbscan <- silhouette(db$cluster, dist(t))
summary(sil.dbscan)
plot(sil.dbscan, col = 2:3, main = "Silhouette plot")

```


```{r scree-plot, fig.cap="Scree Plot", echo=F, fig.width=4, fig.height=4}
Variance<-(pca.out$sdev)^2
max_Var<-round(max(Variance),1)
Components<-c(1:25)
Components<-as.integer(Components)
plot(Components,Variance,main="Scree Plot",xlab="Number of Components",ylab="Variance",type="o",col="blue",ylim=c(0,max_Var),axes=FALSE)
axis(1,at=1:25)
axis(2,at=0:10)
```


The scree plot (Fig \@ref(fig:scree-plot)) shows that most of the variance in the data can be explained in the first 4 principal components. The first 4 principal components were taken to represent the whole dataset.

The ASW for k-means clustering for all cluster numbers was found to be generally lower than that of the unreduced dataset. For 6 clusters, the ASW is 0.3549 and for 2 clusters 0.7914. The value for six clusters is very low to suggest any reasonable regional patterns given that the AWS is low.


```{r echo=F, fig.cap="K-Means PCA data", fig.width=4, fig.height=4}

# Using k-means clustering
k.max <- 10

# data.out <- df_Hmisc_for_clustering[-22,-23]
sil <- rep(0, k.max)
# Compute the average silhouette width for
# k = 2 to k = 10
set.seed(100)
for(i in 2:k.max){
  
  km.res <- kmeans(data.out, centers = i, nstart = 25)
  ss <- silhouette(km.res$cluster, dist(data.out))
  sil[i] <- mean(ss[, 3])
  if (i == 2) {
    clusters_2 = km.res$cluster
  }
  if (i == 6) {
    clusters_6 = km.res$cluster
  }
}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))



# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

# print(sil[6])
# print(sil[2])

```


```{r include=F, fig.cap="HC PCA Clustering Results", fig.width=4, fig.height=4}
# Hierarchical clustering
# Compute pairwise distance matrices
dist.out <- dist(data.out,
                 method = "euclidean")
# Hierarchical clustering results
hc <- hclust(dist.out,
             method = "complete")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc_single <- hclust(dist.out,
             method = "single")
# Visualization of hclust
plot(hc_single, labels = F,-1)
plot(silhouette(cutree(hc_single,6),dist.out))



hc <- hclust(dist.out,
             method = "average")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc <- hclust(dist.out,
             method = "median")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))



hc <- hclust(dist.out,
             method = "centroid")
# Visualization of hclust
plot(hc, labels = F,-1)
plot(silhouette(cutree(hc,6),dist.out))
```



```{r echo=F}
hc_results <- read_excel("HeirachicalResultsHmisc.xlsx")
knitr::kable(hc_results, digits = 5, caption = "Heirachical Clustering Results for the dimensionally reduced data") %>%
  kable_styling(full_width = F, font_size = 7) %>%
  column_spec(1, border_left = T) %>%
  column_spec(2, border_right = T)

tt = tibble(Country = hc[["labels"]], Group = silhouette(cutree(hc_single,6),dist.out)[,1])
```


The ASW for all the hierarchical clustering methods are less than or equal to 0.5 for 6 clusters as shown in Table 5. This also shows that the counties are less likely to be divided ino six continental regions thereby no evidence for regional patterns.


```{r echo=F, fig.cap="K-Mediods PCA Clustering Results", fig.width=4, fig.height=4}
# Using k-medoids clustering
set.seed(100)
pam.out <- pam(data.out, 6)

# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){
  pam.out <- pam(data.out, i)
  sil[i] <- pam.out[["silinfo"]][["avg.width"]]
  if (i==6) {
    class_avg_width = pam.out[["silinfo"]][["clus.avg.widths"]]
    clusters_6 = pam.out$clustering
  }

}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))


# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])

```


The K-mediods method gives an ASW of 0.32 for six clusters. It also suggests that there are probably more than six clusters for the data.


```{r include=F, fig.cap="Clara PCA Clusteing Results", fig.width=4, fig.height=4}
# Using Clara
clara.out <- clara(data.out, 6, samples=10)

# Using k-medoids clustering
set.seed(100)


# Compute the average silhouette width for
# k = 2 to k = 10
for(i in 2:k.max){
  clara.out <- clara(data.out, i, samples=10)
  sil[i] <- clara.out[["silinfo"]][["avg.width"]]
  if (i==6) {
    class_avg_width = clara.out[["silinfo"]][["clus.avg.widths"]]
    clusters_6 = clara.out$clustering
  }
}

clusters_6_dataframe = as.data.frame(clusters_6) %>%
  mutate(continent = df1$continent) %>%
  group_by(continent, clusters_6) %>%
  summarise(count = n()) %>%
  group_by(continent) %>%
  mutate(Percentage = round(count*100/sum(count), digits = 2))

# Plot the average silhouette width
plot(1:k.max,
     sil, type = "b",
     pch = 19,
     frame = FALSE,
     xlab = "Number of clusters k")

abline(v = which.max(sil), lty = 2)

#print(sil[6])
#print(sil[2])
#class_avg_width

```



In general, reducing the dimension of the data led to a worse performance in the clustering algorithms including those for Clara. Therefore, it is best to use the full dataset for clustering.


# Conclusion

The results show that the best algorithm for clustering this data is heirachical single-linkage clustering. Although the clusters show little evidence of regional patterns, the countries in the same cluster show a great similarity as supported by the ASW of 0.83.

The optimum number of clusters is two and this is supported by both heirachical and partition based methods.

\newpage

# References

